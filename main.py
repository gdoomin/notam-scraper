import os
import time
import re
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from supabase import create_client, Client

# --- ì¢Œí‘œ íŒŒì‹± í•¨ìˆ˜ ---
def extract_coords(full_text):
    """Q) ë¼ì¸ì—ì„œ ë„ë¶„(DMS) í˜•íƒœì˜ ì¢Œí‘œë¥¼ ì†Œìˆ˜ì (Decimal)ìœ¼ë¡œ ë³€í™˜"""
    try:
        # Q) ë¼ì¸ì—ì„œ ì¢Œí‘œ íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: 3726N12706E)
        match = re.search(r'(\d{4}[NS])(\d{5}[EW])', full_text)
        if match:
            lat_str, lng_str = match.groups()
            lat = int(lat_str[:2]) + int(lat_str[2:4])/60
            if 'S' in lat_str: lat = -lat
            lng = int(lng_str[:3]) + int(lng_str[3:5])/60
            if 'W' in lng_str: lng = -lng
            return lat, lng
    except:
        pass
    return 37.5665, 126.9780 # ê¸°ë³¸ê°’: ì„œìš¸

def run_scraper():
    # 1. í™˜ê²½ ë³€ìˆ˜ ë° ë¸Œë¼ìš°ì € ì„¤ì •
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    supabase: Client = create_client(url, key)

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    download_dir = os.path.join(os.getcwd(), "downloads")
    if not os.path.exists(download_dir): os.makedirs(download_dir)
    
    prefs = {
        "download.default_directory": download_dir,
        "download.prompt_for_download": False,
        "directory_upgrade": True
    }
    options.add_experimental_option("prefs", prefs)
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    try:
        print("ğŸŒ KOCA ì ‘ì† ì¤‘...")
        driver.get("https://aim.koca.go.kr/xNotam/index.do?type=search2&language=ko_KR")
        time.sleep(10)

        # 2. EXCEL ë²„íŠ¼ í´ë¦­
        print("ğŸ–± EXCEL ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        excel_btn = WebDriverWait(driver, 20).until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(.,'EXCEL')] | //*[@id='btn_excel']"))
        )
        driver.execute_script("arguments[0].click();", excel_btn)
        
        # ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° (ë„‰ë„‰íˆ 30ì´ˆ)
        time.sleep(30)

        # 3. íŒŒì¼ ì½ê¸° ë° ë°ì´í„° ê°€ê³µ
        files = [f for f in os.listdir(download_dir) if f.endswith(('.xls', '.xlsx'))]
        if not files:
            print("ğŸš¨ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        file_path = os.path.join(download_dir, files[-1]) # ê°€ì¥ ìµœê·¼ íŒŒì¼
        print(f"ğŸ“– íŒŒì¼ íŒŒì‹± ì¤‘: {file_path}")
        
        # xlrd ì—”ì§„ì„ ì‚¬ìš©í•˜ì—¬ .xls íŒŒì¼ ì½ê¸°
        df = pd.read_excel(file_path, engine='xlrd')

        update_data = []
        for _, row in df.iterrows():
            notam_id = str(row.get('Notam#', ''))
            full_text = str(row.get('Full Text', ''))
            
            lat, lng = extract_coords(full_text)
            
            update_data.append({
                "notam_id": notam_id,
                "content": full_text,
                "lat": lat,
                "lng": lng,
                "series": notam_id[0] if notam_id else "U",
                "start_date": str(row.get('Start Date UTC', '')),
                "end_date": str(row.get('End Date UTC', ''))
            })

        # 4. Supabase ì €ì¥ (Upsert ë°©ì‹: ì¤‘ë³µì€ ë®ì–´ì“°ê³  ìƒˆê²ƒì€ ì¶”ê°€)
        if update_data:
            supabase.table("notams_excel").upsert(update_data, on_conflict="notam_id").execute()
            print(f"âœ… ì„±ê³µ: {len(update_data)}ê°œì˜ ë…¸íƒ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    run_scraper()
