import os
import time
import re
import shutil
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from supabase import create_client, Client

# 1. ë…¸íƒ ID ì¶”ì¶œìš© ì •ê·œí‘œí˜„ì‹
def find_notam_id_in_source(source):
    match = re.search(r'[A-Z]\d{4}/\d{2}', source)
    return match.group(0) if match else None

def extract_coords(full_text):
    try:
        match = re.search(r'(\d{4}[NS])(\d{5}[EW])', full_text)
        if match:
            lat_str, lng_str = match.groups()
            lat = int(lat_str[:2]) + int(lat_str[2:4])/60
            if 'S' in lat_str: lat = -lat
            lng = int(lng_str[:3]) + int(lng_str[3:5])/60
            if 'W' in lng_str: lng = -lng
            return lat, lng
    except: pass
    return 37.5665, 126.9780

def run_scraper():
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    supabase: Client = create_client(url, key)

    download_dir = os.path.join(os.getcwd(), "downloads")
    if os.path.exists(download_dir):
        shutil.rmtree(download_dir)
    os.makedirs(download_dir)

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    prefs = {
        "download.default_directory": download_dir,
        "profile.default_content_setting_values.multiple_automatic_downloads": 1
    }
    options.add_experimental_option("prefs", prefs)
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.execute_cdp_cmd('Page.setDownloadBehavior', {'behavior': 'allow', 'downloadPath': download_dir})
    wait = WebDriverWait(driver, 60)

    try:
        print(f"ğŸŒ KOCA 345ê±´ ì „ìˆ˜ ìˆ˜ì§‘ ê°€ë™... ({time.strftime('%H:%M:%S')})")
        driver.get("https://aim.koca.go.kr/xNotam/index.do?type=search2&language=ko_KR")
        time.sleep(50) 

        last_page_id = ""

        # ì´ 10í˜ì´ì§€ê¹Œì§€ íƒìƒ‰ (ì‹¤ì œë¡œëŠ” 4í˜ì´ì§€ì—ì„œ ì¢…ë£Œ ì˜ˆìƒ)
        for p in range(1, 11): 
            print(f"ğŸ“„ {p}í˜ì´ì§€ ì‘ì—… ì‹œì‘...")
            
            # í˜„ì¬ í˜ì´ì§€ ID í™•ë³´
            current_id = find_notam_id_in_source(driver.page_source)
            
            if p == 1:
                last_page_id = current_id
                print(f"   -> 1í˜ì´ì§€ ê¸°ì¤€ ID: {last_page_id}")
            else:
                # --- [í•µì‹¬ ìˆ˜ì •] 3í˜ì´ì§€ ëˆ„ë½ ë°©ì§€: ìˆ«ì í…ìŠ¤íŠ¸ ì •ë°€ íƒ€ê²© ---
                try:
                    # ë°©ë²• 1: td ë‚´ë¶€ì— í•´ë‹¹ í˜ì´ì§€ ë²ˆí˜¸ê°€ ì •í™•íˆ ì íŒ ìš”ì†Œë¥¼ ì°¾ìŒ
                    page_xpath = f"//td[contains(@onclick, 'search') and .//font[text()='{p}']]"
                    # ë°©ë²• 2: (ë°±ì—…) í…ìŠ¤íŠ¸ ìì²´ê°€ ìˆ«ìì¸ td
                    fallback_xpath = f"//td[text()='{p}']"
                    
                    try:
                        page_btn = wait.until(EC.presence_of_element_located((By.XPATH, page_xpath)))
                    except:
                        page_btn = wait.until(EC.presence_of_element_located((By.XPATH, fallback_xpath)))

                    # ë²„íŠ¼ ìœ„ì¹˜ë¡œ ì´ë™ ë° ë§ˆìš°ìŠ¤ í´ë¦­
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", page_btn)
                    time.sleep(3)
                    
                    actions = ActionChains(driver)
                    actions.move_to_element(page_btn).click().perform()
                    print(f"   -> {p}í˜ì´ì§€ í´ë¦­ ì™„ë£Œ. ê°±ì‹  í™•ì¸ ì¤‘...")
                    
                    # ë°ì´í„° ê°±ì‹  ê²€ì¦ (IDê°€ ë°”ë€” ë•Œê¹Œì§€ 60ì´ˆê°„ ëŒ€ê¸°)
                    updated = False
                    for _ in range(60):
                        time.sleep(1)
                        new_id = find_notam_id_in_source(driver.page_source)
                        if new_id and new_id != last_page_id:
                            print(f"   -> [í™•ì¸] {p}í˜ì´ì§€ë¡œ ì„±ê³µì  ì´ë™: {last_page_id} -> {new_id}")
                            last_page_id = new_id
                            updated = True
                            break
                    
                    if not updated:
                        print(f"   âš ï¸ {p}í˜ì´ì§€ ê°±ì‹  ì‹¤íŒ¨ (ì´ì „ í˜ì´ì§€ì™€ ë™ì¼). ë‹¤ì‹œ í´ë¦­ ì‹œë„...")
                        driver.execute_script("arguments[0].click();", page_btn) # JSë¡œ ì¬í´ë¦­
                        time.sleep(10)
                        continue # ë‹¤ì‹œ ë£¨í”„ ëŒì•„ì„œ ê°±ì‹  í™•ì¸
                        
                except Exception as e:
                    print(f"   -> {p}í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œë¡œ ê°„ì£¼)")
                    break

            # --- ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (ë§¤ í˜ì´ì§€ í™•ì‹¤íˆ ìˆ˜í–‰) ---
            try:
                excel_xpath = '//*[@id="realContents"]/div[3]/div[1]/div/div/a[3]'
                excel_btn = wait.until(EC.element_to_be_clickable((By.XPATH, excel_xpath)))
                driver.execute_script("arguments[0].click();", excel_btn)
                print(f"   -> {p}í˜ì´ì§€ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì™„ë£Œ")
                
                renamed = False
                for _ in range(60): 
                    time.sleep(1)
                    files = [f for f in os.listdir(download_dir) if not f.startswith('page_') and not f.endswith('.crdownload')]
                    if files:
                        time.sleep(5) # íŒŒì¼ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                        old_path = os.path.join(download_dir, files[0])
                        new_filename = f"page_{p}_notam.xls"
                        os.rename(old_path, os.path.join(download_dir, new_filename))
                        print(f"   -> [í™•ë³´ì„±ê³µ] {new_filename} ({os.path.getsize(os.path.join(download_dir, new_filename))} bytes)")
                        renamed = True
                        break
                if not renamed:
                    print(f"   âš ï¸ {p}í˜ì´ì§€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
            except Exception as e:
                print(f"   âš ï¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}")

        # --- ë°ì´í„° ë³‘í•© ë° ì—…ë¡œë“œ ---
        all_files = sorted([os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.startswith('page_')])
        print(f"ğŸ“‚ ë³‘í•© íŒŒì¼ ëª©ë¡: {[os.path.basename(f) for f in all_files]}")
        
        all_dfs = []
        for f in all_files:
            try:
                df_temp = pd.read_excel(f, engine='xlrd')
                all_dfs.append(df_temp)
                print(f"   -> {os.path.basename(f)}: {len(df_temp)}í–‰ ì½ê¸° ì„±ê³µ")
            except Exception as e:
                print(f"   âš ï¸ {f} ì½ê¸° ì˜¤ë¥˜: {e}")

        if all_dfs:
            full_df = pd.concat(all_dfs, ignore_index=True)
            # Notam# ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
            full_df.drop_duplicates(subset=['Notam#'], keep='first', inplace=True)
            print(f"âœ… ìµœì¢… ë°ì´í„° í†µí•© ì™„ë£Œ: ì´ {len(full_df)}ê±´")

            notam_list = []
            for _, row in full_df.iterrows():
                notam_id = str(row.get('Notam#', ''))
                full_text = str(row.get('Full Text', ''))
                lat, lng = extract_coords(full_text)
                notam_list.append({
                    "notam_id": notam_id, "content": full_text, "lat": lat, "lng": lng,
                    "series": notam_id[0] if notam_id else "U",
                    "start_date": str(row.get('Start Date UTC', '')),
                    "end_date": str(row.get('End Date UTC', ''))
                })
            
            # Supabase ì—…ë¡œë“œ
            supabase.table("notams").upsert(notam_list, on_conflict="notam_id").execute()
            print(f"ğŸš€ [ìµœì¢… ì„±ê³µ] {len(notam_list)}ê±´ì˜ ë°ì´í„°ë¥¼ 'ì½”ìˆ' DBì— ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤!")

    finally:
        driver.quit()

if __name__ == "__main__":
    run_scraper()
