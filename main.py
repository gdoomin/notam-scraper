import os
import time
import re
import shutil
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from supabase import create_client, Client


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def find_notam_id_in_source(source):
    """í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ NOTAM ID ì¶”ì¶œ (í˜ì´ì§€ ì „í™˜ ê°ì§€ìš©)"""
    match = re.search(r'[A-Z]\d{4}/\d{2}', source)
    return match.group(0) if match else None


def extract_coords(full_text):
    """NOTAM ë³¸ë¬¸ì—ì„œ ìœ„/ê²½ë„ ì¶”ì¶œ"""
    try:
        match = re.search(r'(\d{4}[NS])(\d{5}[EW])', full_text)
        if match:
            lat_str, lng_str = match.groups()
            lat = int(lat_str[:2]) + int(lat_str[2:4]) / 60
            if 'S' in lat_str:
                lat = -lat
            lng = int(lng_str[:3]) + int(lng_str[3:5]) / 60
            if 'W' in lng_str:
                lng = -lng
            return lat, lng
    except:
        pass
    return 37.5665, 126.9780


def find_page_button(driver, page_num):
    """
    í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼ì„ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì°¾ëŠ”ë‹¤.
    ì—¬ëŸ¬ XPath ì „ëµì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•œë‹¤.
    """
    strategies = [
        # ì „ëµ 1: í…ìŠ¤íŠ¸ê°€ ì •í™•íˆ í˜ì´ì§€ ë²ˆí˜¸ì¸ td
        f"//table//td[normalize-space(text())='{page_num}']",
        # ì „ëµ 2: a íƒœê·¸ í…ìŠ¤íŠ¸ ê¸°ë°˜
        f"//table//a[normalize-space(text())='{page_num}']",
        # ì „ëµ 3: ì ˆëŒ€ê²½ë¡œ (ê¸°ì¡´ ë°©ì‹, fallback)
        f"/html/body/div[2]/div[3]/div[2]/div/div/div[2]/div[3]/div[2]/div/div/div/div/div/table/tbody/tr[5]/td/div/table/tbody/tr/td[{page_num + 3}]",
    ]

    for xpath in strategies:
        try:
            elements = driver.find_elements(By.XPATH, xpath)
            for el in elements:
                if el.is_displayed() and el.is_enabled():
                    return el
        except:
            continue
    return None


def get_total_pages(driver):
    """
    í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ì—ì„œ ì´ í˜ì´ì§€ ìˆ˜ë¥¼ íŒŒì•…í•œë‹¤.
    ê°ì§€ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ 10 ë°˜í™˜.
    """
    try:
        # í˜ì´ì§€ ë²„íŠ¼ ì˜ì—­ì—ì„œ ìˆ«ì í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        candidates = driver.find_elements(
            By.XPATH,
            "//table//td[string-length(normalize-space(text()))<=2 and normalize-space(text())!='']"
        )
        nums = []
        for el in candidates:
            t = el.text.strip()
            if t.isdigit():
                nums.append(int(t))
        if nums:
            total = max(nums)
            print(f"   -> ì´ {total}í˜ì´ì§€ ìë™ ê°ì§€")
            return total
    except:
        pass
    print("   -> í˜ì´ì§€ ìˆ˜ ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’ 10 ì‚¬ìš©")
    return 10


def wait_for_page_update(driver, old_id, timeout=60):
    """
    í˜ì´ì§€ ì†ŒìŠ¤ê°€ old_idì™€ ë‹¤ë¥¸ NOTAM IDë¥¼ í¬í•¨í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦°ë‹¤.
    ë°˜í™˜: (ì„±ê³µ ì—¬ë¶€, ìƒˆ ID)
    """
    for _ in range(timeout):
        time.sleep(1)
        new_id = find_notam_id_in_source(driver.page_source)
        if new_id and new_id != old_id:
            return True, new_id
    return False, old_id


def click_page_button(driver, btn):
    """ë²„íŠ¼ ìŠ¤í¬ë¡¤ â†’ ActionChains í´ë¦­ â†’ ì‹¤íŒ¨ ì‹œ JS í´ë¦­"""
    try:
        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", btn)
        time.sleep(2)
        ActionChains(driver).move_to_element(btn).click().perform()
        return True
    except:
        pass
    try:
        driver.execute_script("arguments[0].click();", btn)
        return True
    except:
        return False


def download_excel(driver, wait, download_dir, page_num, timeout=90):
    """
    í˜„ì¬ í˜ì´ì§€ì˜ ì—‘ì…€ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  page_N_notam.xls ë¡œ ì €ì¥.
    ë°˜í™˜: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ or None
    """
    try:
        excel_xpath = '//*[@id="realContents"]/div[3]/div[1]/div/div/a[3]'
        excel_btn = wait.until(EC.element_to_be_clickable((By.XPATH, excel_xpath)))
        driver.execute_script("arguments[0].click();", excel_btn)
        print(f"   -> {page_num}í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­")
    except Exception as e:
        print(f"   âš ï¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}")
        return None

    for _ in range(timeout):
        time.sleep(1)
        files = [
            f for f in os.listdir(download_dir)
            if not f.startswith('page_') and not f.endswith('.crdownload')
        ]
        if files:
            time.sleep(3)  # íŒŒì¼ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸°
            old_path = os.path.join(download_dir, files[0])
            new_filename = f"page_{page_num}_notam.xls"
            new_path = os.path.join(download_dir, new_filename)
            os.rename(old_path, new_path)
            size = os.path.getsize(new_path)
            print(f"   -> [í™•ë³´] {new_filename} ({size} bytes)")
            return new_path

    print(f"   âš ï¸ {page_num}í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ")
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ìŠ¤í¬ë˜í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_scraper():
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    supabase: Client = create_client(url, key)

    # ë‹¤ìš´ë¡œë“œ í´ë” ì´ˆê¸°í™”
    download_dir = os.path.join(os.getcwd(), "downloads")
    if os.path.exists(download_dir):
        shutil.rmtree(download_dir)
    os.makedirs(download_dir)

    # Chrome ì˜µì…˜
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    prefs = {
        "download.default_directory": download_dir,
        "profile.default_content_setting_values.multiple_automatic_downloads": 1,
    }
    options.add_experimental_option("prefs", prefs)

    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()), options=options
    )
    driver.execute_cdp_cmd(
        'Page.setDownloadBehavior',
        {'behavior': 'allow', 'downloadPath': download_dir}
    )
    wait = WebDriverWait(driver, 60)

    try:
        print(f"ğŸŒ KOCA NOTAM ìˆ˜ì§‘ ì‹œì‘... ({time.strftime('%H:%M:%S')})")
        driver.get("https://aim.koca.go.kr/xNotam/index.do?type=search2&language=ko_KR")
        print("   -> ì´ˆê¸° í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (55ì´ˆ)...")
        time.sleep(55)

        # â”€â”€ 1í˜ì´ì§€ ì²˜ë¦¬ â”€â”€
        print("ğŸ“„ 1í˜ì´ì§€ ìˆ˜ì§‘ ì‘ì—… ì‹œì‘...")
        last_id = find_notam_id_in_source(driver.page_source)
        print(f"   -> 1í˜ì´ì§€ ID í™•ë³´: {last_id}")
        download_excel(driver, wait, download_dir, 1)

        # â”€â”€ ì´ í˜ì´ì§€ ìˆ˜ íŒŒì•… â”€â”€
        total_pages = get_total_pages(driver)

        # â”€â”€ 2í˜ì´ì§€ ì´í›„ ì²˜ë¦¬ â”€â”€
        for p in range(2, total_pages + 1):
            print(f"ğŸ“„ {p}í˜ì´ì§€ ìˆ˜ì§‘ ì‘ì—… ì‹œì‘...")

            # 1) í˜ì´ì§€ ë²„íŠ¼ íƒìƒ‰ (ìµœëŒ€ 30ì´ˆ)
            page_btn = None
            for attempt in range(30):
                page_btn = find_page_button(driver, p)
                if page_btn:
                    break
                time.sleep(1)

            if not page_btn:
                print(f"   -> {p}í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ì¢…ë£Œ.")
                break

            # 2) ë²„íŠ¼ í´ë¦­
            clicked = click_page_button(driver, page_btn)
            if not clicked:
                print(f"   -> {p}í˜ì´ì§€ í´ë¦­ ì‹¤íŒ¨. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            print(f"   -> {p}í˜ì´ì§€ í´ë¦­ ì™„ë£Œ. ê°±ì‹  í™•ì¸ ì¤‘...")

            # 3) í˜ì´ì§€ ê°±ì‹  ëŒ€ê¸° (ìµœëŒ€ 60ì´ˆ)
            updated, new_id = wait_for_page_update(driver, last_id, timeout=60)

            if updated:
                print(f"   -> [ì„±ê³µ] ë°ì´í„° êµì²´ í™•ì¸: {last_id} -> {new_id}")
                last_id = new_id
            else:
                # JS ê°•ì œ í´ë¦­ ì¬ì‹œë„
                print(f"   âš ï¸ ê°±ì‹  ë¯¸í™•ì¸. JS ê°•ì œ í´ë¦­ ì¬ì‹œë„...")
                try:
                    page_btn = find_page_button(driver, p)
                    if page_btn:
                        driver.execute_script("arguments[0].click();", page_btn)
                except:
                    pass

                updated, new_id = wait_for_page_update(driver, last_id, timeout=30)

                if updated:
                    print(f"   -> [JS ì¬ì‹œë„ ì„±ê³µ] {last_id} -> {new_id}")
                    last_id = new_id
                else:
                    print(f"   âš ï¸ {p}í˜ì´ì§€ ê°±ì‹  ìµœì¢… ì‹¤íŒ¨. ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µ.")
                    continue  # ê°™ì€ ë°ì´í„° ì¤‘ë³µ ì €ì¥ ë°©ì§€ë¥¼ ìœ„í•´ ê±´ë„ˆëœ€

            # 4) ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            download_excel(driver, wait, download_dir, p)

        # â”€â”€ ë°ì´í„° ë³‘í•© â”€â”€
        all_files = sorted([
            os.path.join(download_dir, f)
            for f in os.listdir(download_dir)
            if f.startswith('page_')
        ])
        print(f"\nğŸ“‚ ë³‘í•© íŒŒì¼ ëª©ë¡: {[os.path.basename(f) for f in all_files]}")

        all_dfs = []
        for f in all_files:
            try:
                df_temp = pd.read_excel(f, engine='xlrd')
                all_dfs.append(df_temp)
                print(f"   -> {os.path.basename(f)}: {len(df_temp)}í–‰ ì¶”ê°€")
            except Exception as e:
                print(f"   âš ï¸ {os.path.basename(f)} ì½ê¸° ì‹¤íŒ¨: {e}")
                continue

        if not all_dfs:
            print("âŒ ìˆ˜ì§‘ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        full_df = pd.concat(all_dfs, ignore_index=True)
        full_df.drop_duplicates(subset=['Notam#'], keep='first', inplace=True)
        print(f"âœ… ìµœì¢… ë°ì´í„° í™•ë³´: ì´ {len(full_df)}ê±´")

        # â”€â”€ Supabase ë™ê¸°í™” â”€â”€
        notam_list = []
        for _, row in full_df.iterrows():
            notam_id = str(row.get('Notam#', ''))
            full_text = str(row.get('Full Text', ''))
            lat, lng = extract_coords(full_text)
            notam_list.append({
                "notam_id": notam_id,
                "content": full_text,
                "lat": lat,
                "lng": lng,
                "series": notam_id[0] if notam_id else "U",
                "start_date": str(row.get('Start Date UTC', '')),
                "end_date": str(row.get('End Date UTC', '')),
            })

        print("ğŸ§¹ ì´ì „ ë…¸íƒ ì²­ì†Œ ì¤‘...")
        supabase.table("notams").delete().neq("notam_id", "0").execute()

        # ëŒ€ëŸ‰ upsert ì‹œ ë°°ì¹˜ ì²˜ë¦¬ (ì•ˆì •ì„± í–¥ìƒ)
        BATCH_SIZE = 100
        for i in range(0, len(notam_list), BATCH_SIZE):
            batch = notam_list[i:i + BATCH_SIZE]
            supabase.table("notams").upsert(batch, on_conflict="notam_id").execute()
            print(f"   -> {i + len(batch)}/{len(notam_list)}ê±´ ì—…ë¡œë“œ ì™„ë£Œ")

        print(f"ğŸš€ [ìµœì¢… ì„±ê³µ] {len(notam_list)}ê±´ì˜ ë°ì´í„°ë¥¼ DBì— ë°˜ì˜í–ˆìŠµë‹ˆë‹¤!")

    finally:
        driver.quit()


if __name__ == "__main__":
    run_scraper()
