import os
import time
import re
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from supabase import create_client, Client

def extract_coords(full_text):
    try:
        match = re.search(r'(\d{4}[NS])(\d{5}[EW])', full_text)
        if match:
            lat_str, lng_str = match.groups()
            lat = int(lat_str[:2]) + int(lat_str[2:4])/60
            if 'S' in lat_str: lat = -lat
            lng = int(lng_str[:3]) + int(lng_str[3:5])/60
            if 'W' in lng_str: lng = -lng
            return lat, lng
    except: pass
    return 37.5665, 126.9780

def run_scraper():
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    supabase: Client = create_client(url, key)

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    download_dir = os.path.join(os.getcwd(), "downloads")
    if not os.path.exists(download_dir): os.makedirs(download_dir)
    prefs = {"download.default_directory": download_dir, "safebrowsing.enabled": True}
    options.add_experimental_option("prefs", prefs)
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    try:
        print("ğŸŒ KOCA í˜ì´ì§€ ì ‘ì† ì¤‘...")
        driver.get("https://aim.koca.go.kr/xNotam/index.do?type=search2&language=ko_KR")
        
        # 1. ì¶©ë¶„í•œ ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        wait = WebDriverWait(driver, 30)
        time.sleep(20) 

        print("ğŸ¯ ì œê³µëœ XPathë¡œ ì—‘ì…€ ë²„íŠ¼ ì •ë°€ ì¡°ì¤€...")
        target_xpath = '//*[@id="realContents"]/div[3]/div[1]/div/div/a[3]'
        
        try:
            # 2. ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸° í›„ ê°€ì ¸ì˜¤ê¸°
            excel_btn = wait.until(EC.presence_of_element_located((By.XPATH, target_xpath)))
            
            # 3. í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ (í´ë¦­ ë¯¸ìŠ¤ ë°©ì§€)
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", excel_btn)
            time.sleep(2)
            
            # 4. ì¼ë°˜ í´ë¦­ ì‹œë„ í›„ ì•ˆë˜ë©´ JS í´ë¦­
            try:
                excel_btn.click()
                print("âœ… ì¼ë°˜ í´ë¦­ ì„±ê³µ")
            except:
                driver.execute_script("arguments[0].click();", excel_btn)
                print("âœ… ìë°”ìŠ¤í¬ë¦½íŠ¸ ê°•ì œ í´ë¦­ ì„±ê³µ")
                
        except Exception as e:
            print(f"ğŸš¨ XPathë¡œ ë²„íŠ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
            driver.save_screenshot("xpath_error.png")
            # ë””ë²„ê¹…ì„ ìœ„í•´ í˜ì´ì§€ ë‚´ ëª¨ë“  'a' íƒœê·¸ ê°¯ìˆ˜ ì¶œë ¥
            links = driver.find_elements(By.TAG_NAME, "a")
            print(f"ğŸ’¡ í˜„ì¬ í˜ì´ì§€ ë‚´ ì´ {len(links)}ê°œì˜ ë§í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
            return

        print("â³ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° (40ì´ˆ)...")
        time.sleep(40)

        # 5. íŒŒì¼ í™•ì¸ ë° ì²˜ë¦¬
        files = [f for f in os.listdir(download_dir) if f.endswith(('.xls', '.xlsx'))]
        if not files:
            print("ğŸš¨ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ëª©ë¡:", os.listdir(download_dir))
            return

        file_path = os.path.join(download_dir, files[-1])
        df = pd.read_excel(file_path, engine='xlrd')
        
        notam_list = []
        for _, row in df.iterrows():
            notam_id = str(row.get('Notam#', ''))
            full_text = str(row.get('Full Text', ''))
            lat, lng = extract_coords(full_text)
            
            notam_list.append({
                "notam_id": notam_id,
                "content": full_text,
                "lat": lat,
                "lng": lng,
                "series": notam_id[0] if notam_id else "U",
                "start_date": str(row.get('Start Date UTC', '')),
                "end_date": str(row.get('End Date UTC', ''))
            })

        if notam_list:
            supabase.table("notams").upsert(notam_list, on_conflict="notam_id").execute()
            print(f"âœ… ì„±ê³µ: {len(notam_list)}ê°œì˜ ì—‘ì…€ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

    except Exception as e:
        print(f"ğŸš¨ ì—ëŸ¬: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    run_scraper()
